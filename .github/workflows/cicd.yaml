name: Run AI Linkedin Job Scraper

on:
  push:
      branches:
        - main
  schedule:
    # Runs at minute 0 past hour 0 and 12 (Every 12 hours)
    - cron: '0 0,12 * * *'
  workflow_dispatch:

jobs:
  scrape-and-validate:
    runs-on: ubuntu-latest
    
    env:
      UV_SYSTEM_PYTHON: 1

    steps:
      # 1. Checkout Code
      - name: Checkout repository
        uses: actions/checkout@v4

      # 2. Install uv
      - name: Install uv
        uses: astral-sh/setup-uv@v3
        with:
          enable-cache: true
          cache-dependency-glob: "uv.lock"

      # 3. Set up Python
      - name: Set up Python 3.12
        run: uv python install 3.12

      # 4. Install Dependencies
      - name: Install project dependencies
        run: uv sync --frozen
        # If no uv.lock exists yet, use: run: uv sync

      # 5. Run the Orchestrator with Env Vars
      - name: Run Orchestrator Script
        env:
          # Application Secrets
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          LINKEDIN_COOKIE: ${{ secrets.LINKEDIN_COOKIE }}
          
          # Google Cloud Secrets
          GOOGLE_CLOUD_PROJECT_ID: ${{ secrets.GOOGLE_CLOUD_PROJECT_ID }}
          GOOGLE_CLOUD_PRIVATE_KEY: ${{ secrets.GOOGLE_CLOUD_PRIVATE_KEY }}
          GOOGLE_CLOUD_CLIENT_EMAIL: ${{ secrets.GOOGLE_CLOUD_CLIENT_EMAIL }}
          
          # Config
          PYTHONPATH: .
        run: |
          uv run python job_agent/linkedin/orchestrator.py